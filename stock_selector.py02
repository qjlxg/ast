import akshare as ak 
import pandas as pd
import numpy as np
from datetime import datetime
import os
import asyncio
import mplfinance as mpf
import nest_asyncio

# 启用 nest_asyncio
nest_asyncio.apply()

# 名称缓存文件路径
STOCK_NAMES_CACHE_FILE = 'stock_names_cache.csv'

# 设置 MPLFINANCE 的中文字体（在 Linux 环境下，例如 GitHub Actions）
MPF_FONT_NAME = 'WenQuanYi Zen Hei'
MPF_FONT_SIZE = 12

# --- 全局结果路径配置 ---

# 获取当前日期和时间 (已在 YAML 中设置 TZ=Asia/Shanghai)
CURRENT_DATETIME = datetime.now()
# 年月目录 (例如: 202510)
DATE_MONTH_DIR = CURRENT_DATETIME.strftime('%Y%m')
# 文件名前缀 (例如: 20251020_204702)
DATE_TIME_PREFIX = CURRENT_DATETIME.strftime('%Y%m%d_%H%M%S')
# 结果保存的根目录
RESULTS_ROOT_DIR = 'screening_results'
# 当次运行结果保存的年月目录
OUTPUT_DIR = os.path.join(RESULTS_ROOT_DIR, DATE_MONTH_DIR)
# K线图保存的子目录
K_LINE_PLOTS_DIR = os.path.join(OUTPUT_DIR, 'k_line_plots')
# 错误日志文件名
ERROR_LOG_FILE = os.path.join(OUTPUT_DIR, f'{DATE_TIME_PREFIX}_error_log.txt')
# 筛选结果文件名
SELECTED_STOCKS_FILE = os.path.join(OUTPUT_DIR, f'{DATE_TIME_PREFIX}_selected_stocks.csv')
# 筛选结果文件名 (中间/临时文件，文件名和最终结果相同)
SELECTED_STOCKS_INTERMEDIATE_FILE = os.path.join(OUTPUT_DIR, f'{DATE_TIME_PREFIX}_selected_stocks_intermediate.csv')


# --- 辅助函数 (保持不变) ---

def get_stock_name_map(local_codes):
    """
    获取股票代码-名称映射，支持缓存和网络更新。
    """
    name_map = {}
    codes_to_fetch = set(local_codes)
    all_ak_map = {} 

    # 1. 尝试从缓存读取
    if os.path.exists(STOCK_NAMES_CACHE_FILE):
        try:
            cache_df = pd.read_csv(STOCK_NAMES_CACHE_FILE, dtype={'code': str}, encoding='utf-8-sig')
            if 'code' in cache_df.columns and 'name' in cache_df.columns:
                
                cache_df['code'] = cache_df['code'].str.zfill(6)
                cached_map = cache_df.set_index('code')['name'].to_dict()
                all_ak_map.update(cached_map)
                
                for code in local_codes:
                    if code in cached_map and cached_map[code] != '未知': 
                        name_map[code] = cached_map[code]
                        codes_to_fetch.discard(code) 
                        
                print(f"[{datetime.now()}] [INFO] Loaded {len(cached_map)} names from cache. {len(codes_to_fetch)} codes need update.", flush=True)

        except Exception as e:
            print(f"[{datetime.now()}] [WARNING] Failed to read cache {STOCK_NAMES_CACHE_FILE}: {str(e)}. Will refresh all.", flush=True)
            codes_to_fetch = set(local_codes) 
            name_map = {}

    # 2. 如果有代码缺失或缓存失败，则从 akshare 获取最新全市场数据
    if codes_to_fetch or not os.path.exists(STOCK_NAMES_CACHE_FILE):
        
        # 2.1 尝试使用全面的 A 股列表 (stock_info_a_code_name)
        try:
            print(f"[{datetime.now()}] [INFO] Fetching stock names from akshare (via stock_info_a_code_name)...", flush=True)
            all_a_stocks = ak.stock_info_a_code_name() 
            all_a_stocks['code'] = all_a_stocks['code'].astype(str).str.zfill(6)
            ak_map_main = all_a_stocks.set_index('code')['name'].to_dict()
            all_ak_map.update(ak_map_main)
            print(f"[{datetime.now()}] [INFO] Akshare fetched {len(ak_map_main)} names from main list.", flush=True)

        except Exception as e:
            print(f"[{datetime.now()}] [ERROR] Failed to fetch main stock names from akshare: {str(e)}", flush=True)
        
        # 2.2 尝试使用次新股和新股列表补充 (stock_zh_a_new_code_name)
        try:
            print(f"[{datetime.now()}] [INFO] Fetching names from akshare (via stock_zh_a_new_code_name)...", flush=True)
            new_stocks = ak.stock_zh_a_new_code_name()
            # 字段名可能不同，这里使用 '代码' 和 '名称'
            new_stocks['code'] = new_stocks['代码'].astype(str).str.zfill(6)
            ak_map_new = new_stocks.set_index('代码')['名称'].to_dict() # 注意此处字段可能变动
            all_ak_map.update(ak_map_new) 
            print(f"[{datetime.now()}] [INFO] Akshare fetched {len(ak_map_new)} names from new list.", flush=True)
            
        except Exception as e:
            print(f"[{datetime.now()}] [ERROR] Failed to fetch new stock names from akshare: {str(e)}", flush=True)

        # 2.3 增加备用接口：使用 stock_zh_a_spot_em 获取实时股票数据补充名称
        try:
            print(f"[{datetime.now()}] [INFO] Fetching names from akshare (via stock_zh_a_spot_em)...", flush=True)
            spot_stocks = ak.stock_zh_a_spot_em()
            spot_stocks['code'] = spot_stocks['代码'].astype(str).str.zfill(6)
            ak_map_spot = spot_stocks.set_index('代码')['名称'].to_dict()
            all_ak_map.update(ak_map_spot)
            print(f"[{datetime.now()}] [INFO] Akshare fetched {len(ak_map_spot)} names from spot list.", flush=True)
        except Exception as e:
            print(f"[{datetime.now()}] [ERROR] Failed to fetch spot stock names from akshare: {str(e)}", flush=True)

        # 3. 合并新获取的名称到 name_map 中 (只更新需要更新的代码)
        fetched_codes_count = 0
        for code in codes_to_fetch.copy(): 
            fetched_name = all_ak_map.get(code)
            if fetched_name:
                name_map[code] = fetched_name
                codes_to_fetch.discard(code)
                fetched_codes_count += 1
                
        print(f"[{datetime.now()}] [INFO] Successfully matched {fetched_codes_count} names from Akshare network fetch.", flush=True)

        # 4. 更新缓存文件 (写入所有 akshare 获取到的最新数据)
        if all_ak_map:
            new_cache_df = pd.DataFrame(list(all_ak_map.items()), columns=['code', 'name'])
            new_cache_df['code'] = new_cache_df['code'].astype(str).str.zfill(6)
            new_cache_df.drop_duplicates(subset=['code'], keep='last', inplace=True)
            new_cache_df.to_csv(STOCK_NAMES_CACHE_FILE, index=False, encoding='utf-8-sig')
            print(f"[{datetime.now()}] [INFO] Cache file {STOCK_NAMES_CACHE_FILE} updated with {len(new_cache_df)} entries.", flush=True)
        else:
            print(f"[{datetime.now()}] [WARNING] Akshare fetch failed entirely. Cache not updated.", flush=True)

    # 5. 确保所有本地代码都有名称
    final_map = {}
    for code in local_codes:
        final_map[code] = name_map.get(code) or all_ak_map.get(code) or '未知'
        
    # 6. 记录仍未匹配的代码
    unmatched_codes = [code for code in local_codes if final_map[code] == '未知']
    if unmatched_codes:
        print(f"[{datetime.now()}] [WARNING] {len(unmatched_codes)} codes still unmatched: {unmatched_codes}", flush=True)
        with open(ERROR_LOG_FILE, 'a', encoding='utf-8') as f:
            f.write(f"[{datetime.now()}] [WARNING] Unmatched codes: {unmatched_codes}\n")
    
    return final_map


def get_stock_list():
    """扫描本地数据，并获取名称。"""
    stock_data_dir = 'stock_data'
    if not os.path.exists(stock_data_dir):
        print(f"[{datetime.now()}] [ERROR] Directory '{stock_data_dir}' not found. Cannot load stock list.", flush=True)
        return pd.DataFrame(columns=['ts_code', 'name'])

    
    files = [f for f in os.listdir(stock_data_dir) if f.endswith('.csv')]
    local_codes = set(f.replace('.csv', '') for f in files)
    
    if not local_codes:
        print(f"[{datetime.now()}] [WARNING] No valid CSV files found in 'stock_data' directory.", flush=True)
        return pd.DataFrame(columns=['ts_code', 'name'])

    name_map = get_stock_name_map(local_codes)
    
    stock_list_data = []
    for code in local_codes:
        stock_name = name_map.get(code, '未知')
        ts_code = f"{code}.SS" if code.startswith('6') else f"{code}.SZ"
        stock_list_data.append({'ts_code': ts_code, 'name': stock_name})

    stock_list = pd.DataFrame(stock_list_data).drop_duplicates(subset=['ts_code'])
    
    print(f"[{datetime.now()}] [INFO] Local directory successfully matched {len(stock_list)} stocks with names.", flush=True)
    
    return stock_list[['ts_code', 'name']]


def is_limit_up(close, pre_close):
    """判断是否涨停 (涨幅 >=9.9%)"""
    if pre_close <= 0:
        return False
    return (close / pre_close - 1) >= 0.099

def plot_k_line(df, ts_code, name):
    """生成 K 线图，包含 5/10/13 日均线、20 日成交量均线"""
    if not os.path.exists(K_LINE_PLOTS_DIR):
        os.makedirs(K_LINE_PLOTS_DIR)
    
    df = df.copy()
    
    if '日期' in df.columns:
        df['日期'] = pd.to_datetime(df['日期'])
        df.set_index('日期', inplace=True)
    elif not isinstance(df.index, pd.DatetimeIndex):
        df.index = pd.to_datetime(df.index)
        
    # 确保列名与 mplfinance 要求一致
    required_cols = ['开盘', '最高', '最低', '收盘', '成交量', 'MA5', 'MA10', 'MA13', 'VOL_MA20'] # 增加 MA13
    df = df.reindex(columns=required_cols).rename(columns={
        '开盘': 'Open', '最高': 'High', '最低': 'Low', '收盘': 'Close', '成交量': 'Volume'
    })
    
    # 准备涨停点
    df_temp = df.copy()
    df_temp['Pre_Close'] = df_temp['Close'].shift(1)
    df_temp['Is_Limit_Up'] = df_temp.apply(lambda row: is_limit_up(row['Close'], row['Pre_Close']), axis=1)
    
    limit_up_dates_dt = df_temp[df_temp['Is_Limit_Up']].index.tolist()
    limit_up_points = [(date, df.loc[date, 'High']) for date in limit_up_dates_dt if date in df.index]
    
    # 均线和成交量均线
    apds = [
        mpf.make_addplot(df['MA5'], color='blue', label='MA5'),
        mpf.make_addplot(df['MA10'], color='red', label='MA10'),
        mpf.make_addplot(df['MA13'], color='green', label='MA13'), # 新增
        mpf.make_addplot(df['VOL_MA20'], color='purple', panel=1, label='VOL_MA20'),
    ]
    
    # 涨停标记
    if limit_up_points:
        scatter_series = pd.Series([p[1] for p in limit_up_points], index=[p[0] for p in limit_up_points])
        apds.append(mpf.make_addplot(
            scatter_series,
            type='scatter', markersize=100, marker='^', color='darkgreen', label='Limit Up'
        ))
    
    # 配置中文字体
    mc = mpf.make_marketcolors(up='red', down='green', inherit=True)
    s = mpf.make_mpf_style(base_mpf_style='yahoo', marketcolors=mc,
                            rc={'font.sans-serif': MPF_FONT_NAME, 
                                'font.size': MPF_FONT_SIZE, 
                                'axes.unicode_minus': False} 
                          )

    file_name = f"{ts_code}_{name}.png" if name and name != '未知' else f"{ts_code}.png"
    mpf.plot(
        df, type='candle', addplot=apds, volume=True,
        title=f"{ts_code} {name}", style=s,
        savefig=os.path.join(K_LINE_PLOTS_DIR, file_name)
    )


def fetch_stock_data_sync(code, *args, **kwargs):
    """同步获取股票日线数据，从本地 stock_data 目录读取 CSV 文件。"""
    file_path = os.path.join('stock_data', f'{code}.csv')
    
    if not os.path.exists(file_path):
        return code, None, f"Local data file not found: {file_path}"
    
    try:
        try:
            df = pd.read_csv(file_path, parse_dates=['日期'], encoding='utf-8')
        except UnicodeDecodeError:
            df = pd.read_csv(file_path, parse_dates=['日期'], encoding='gbk')
        
        required_cols = ['日期', '开盘', '最高', '最低', '收盘', '成交量']
        
        if '股票代码' in df.columns:
            df = df.rename(columns={'股票代码': 'code'})
        
        if not all(col in df.columns for col in required_cols):
            return code, None, f"Local data file missing required columns. Found: {list(df.columns)}"
        
        if not df.empty and '日期' in df.columns and '收盘' in df.columns:
            df = df[required_cols]
            return code, df, None
        
        return code, None, "Local data file is empty or incomplete."

    except Exception as e:
        return code, None, f"Error reading local data file {file_path}: {str(e)}"

def fetch_data_and_pre_check(code, *args, **kwargs):
    """同步获取股票日线数据 (从本地)，并进行 5-20 日涨停预检查。"""
    
    code, df, error = fetch_stock_data_sync(code)
    
    # 预筛选周期为最近 5~20 天 (0-4天留给回调观察)
    if error or df.empty or len(df) < 21:
        return code, False, error
    
    try:
        df = df.sort_values('日期').reset_index(drop=True)
        
        # 预筛选范围： D-5 到 D-20 (索引 -5 到 -20)
        # i 从 5 到 20
        for i in range(5, 21): 
            
            if len(df) <= i:
                continue
                
            curr_day = df.iloc[-i] 
            if len(df) <= i + 1:
                continue

            prev_day = df.iloc[-i - 1] 
            
            if is_limit_up(curr_day['收盘'], prev_day['收盘']):
                return code, True, None # 预筛选通过
        
        return code, False, None # 未通过预筛选
        
    except Exception as e:
        return code, False, f"Pre-check logic error: {str(e)}"

# --- 核心筛选函数 (已恢复为最严格版本) ---

async def screen_stocks(stock_list, days=35): 
    
    # =========================================================
    # PHASE 1: Pre-Screening (5-20 day limit-up)
    # =========================================================
    
    if stock_list.empty:
        print(f"[{datetime.now()}] Stock list is empty. Screening skipped.", flush=True)
        return pd.DataFrame()

    print(f"\n[{datetime.now()}] --- PHASE 1: Pre-screening {len(stock_list)} stocks for 5-20 day limit-up ---", flush=True)
    
    pre_screen_tasks = []
    
    for _, stock in stock_list.iterrows():
        code = stock['ts_code'].split('.')[0]
        task = asyncio.to_thread(fetch_data_and_pre_check, code) 
        pre_screen_tasks.append(task)
        
    candidate_codes = []
    error_log_p1 = []
    
    for index, future in enumerate(asyncio.as_completed(pre_screen_tasks)):
        code, passed, error = await future
        
        if passed:
            candidate_codes.append(code)
        
        if (index + 1) % 100 == 0 or index == len(stock_list) - 1:
            print(f"[{datetime.now()}] [PROGRESS-P1] Checked {index + 1}/{len(stock_list)}. Candidates found: {len(candidate_codes)}", flush=True)
            
        if error:
            error_log_p1.append(f"Error in pre-check for {code}: {error}")

    candidate_stock_list = stock_list[stock_list['ts_code'].str.split('.').str[0].isin(candidate_codes)].copy()
    
    print(f"[{datetime.now()}] --- PHASE 1 COMPLETED. Found {len(candidate_stock_list)} candidates. ---", flush=True)

    if candidate_stock_list.empty:
        print(f"[{datetime.now()}] No stocks passed the 5-20 day limit-up pre-screen. Screening finished.", flush=True)
        with open(ERROR_LOG_FILE, 'a', encoding='utf-8') as f:
            for log in error_log_p1:
                f.write(f"[{datetime.now()}] [P1 Error] {log}\n")
        return pd.DataFrame()

    # =========================================================
    # PHASE 2: Detailed Screening (Strict Call-Back Strategy)
    # =========================================================
    
    print(f"\n[{datetime.now()}] --- PHASE 2: Detailed screening on {len(candidate_stock_list)} candidates (Strict Call-Back Strategy) ---", flush=True)
    
    detailed_screen_tasks = []
    selected = []
    error_log_p2 = []
    
    for _, stock in candidate_stock_list.iterrows():
        code = stock['ts_code'].split('.')[0]
        task = asyncio.to_thread(fetch_stock_data_sync, code) 
        detailed_screen_tasks.append(task)
        
    total_candidates = len(candidate_stock_list)
    
    for index, future in enumerate(asyncio.as_completed(detailed_screen_tasks)):
        code, df, error = await future
        
        ts_code = f"{code}.SS" if code.startswith('6') else f"{code}.SZ"
        name = candidate_stock_list.set_index('ts_code').loc[ts_code, 'name'] if ts_code in candidate_stock_list.set_index('ts_code').index else '未知'

        status_msg = f"[{datetime.now()}] [PROGRESS-P2] {index+1}/{total_candidates} | Checking {ts_code} ({name})"
        
        if error:
            error_log_p2.append(f"Error processing {ts_code}: {error}")
            print(f"{status_msg} - FAILED (Data Error)", flush=True)
            continue
            
        if df.empty or len(df) < days + 1:
            error_log_p2.append(f"Skipping {ts_code}: Insufficient data ({len(df)} days). Required: {days + 1}")
            print(f"{status_msg} - SKIPPED (Data Insufficient)", flush=True)
            continue
        
        try:
            # --- 数据准备及指标计算 ---
            df = df.sort_values('日期').reset_index(drop=True)
            df['日期'] = pd.to_datetime(df['日期'])
            df['trade_date'] = df['日期'].dt.strftime('%Y%m%d')
            
            # 计算指标
            df['VOL_MA5'] = df['成交量'].rolling(5).mean()
            df['MA5'] = df['收盘'].rolling(5).mean()
            df['MA10'] = df['收盘'].rolling(10).mean()
            df['MA13'] = df['收盘'].rolling(13).mean() 
            df['pre_high_20'] = df['最高'].rolling(window=20, closed='left').max()
            df['VOL_MA20'] = df['成交量'].rolling(20).mean()
            
            df_slice = df.iloc[-(days + 1):].copy().reset_index(drop=True)
            df_recent = df_slice.iloc[1:].copy() 
            df_recent['Pre_Close'] = df_slice['收盘'].shift(1).iloc[1:] 
            
            curr = df_recent.iloc[-1]
            signal = None
            trigger_day_data = None
            
            
            # --- 1. 寻找最近的“放量大阳线涨停突破前高”日 (D-5 到 D-20) ---
            search_window = df_recent.iloc[-20:-4] 
            
            for i in range(len(search_window) - 1, -1, -1):
                lu_day = search_window.iloc[i]
                
                # 1a. 涨停
                is_lu = is_limit_up(lu_day['收盘'], lu_day['Pre_Close'])
                
                # 1b. 大阳线实体 (收盘价 > 开盘价)
                is_large_body = lu_day['收盘'] > lu_day['开盘']
                
                # 1c. 突破前高
                is_breakout = lu_day['收盘'] > lu_day['pre_high_20']
                
                # 1d. 放量 (成交量 > 20日均量)
                is_vol_heavy = lu_day['成交量'] > lu_day['VOL_MA20']
                
                if is_lu and is_large_body and is_breakout and is_vol_heavy:
                    trigger_day_data = lu_day
                    break # 找到最近一个符合条件的突破日

            
            if trigger_day_data is not None:
                trigger_idx = df_recent.index.get_loc(trigger_day_data.name)
                
                # 回调周期：从突破日后的第一天（trigger_idx + 1）到昨天（-1）
                callback_period = df_recent.iloc[trigger_idx + 1: -1].copy() 
                
                # --- 2. 检查回踩周期和不破位条件 (严格版) ---
                
                # ***** 恢复点 1: 恢复最长回调时间至 10 天 *****
                if len(callback_period) > 10: 
                    print(f"{status_msg} - NO MATCH (Failed: Callback period > 10 days)", flush=True)
                    continue 

                # 2b. 回调过程中不能跌破涨停阳线实体下沿 (开盘价)
                if not callback_period.empty and (callback_period['最低'] < trigger_day_data['开盘']).any():
                    print(f"{status_msg} - NO MATCH (Failed: Broke LU Day Open Price during callback)", flush=True)
                    continue
                
                # --- 3. 检查地量确认条件 (严格版) ---
                
                # ***** 恢复点 2: 恢复极度缩量条件至 MA5/3 *****
                # 极度缩量日：成交量 < 5日均量的 1/3
                has_extreme_shrink = (callback_period['成交量'] < callback_period['VOL_MA5'] / 3).any()
                
                if not has_extreme_shrink:
                    print(f"{status_msg} - NO MATCH (Failed: No extreme volume shrink (Vol < MA5/3) found)", flush=True)
                    continue
                
                # --- 4. 检查当前买点确认条件 (保持不变) ---
                
                # 4a. 确认当前 D0 收盘价仍在涨停板阳线实体的下沿之上
                if curr['收盘'] < trigger_day_data['开盘']:
                    print(f"{status_msg} - NO MATCH (Failed: D0 Close Price Broke LU Day Open Price)", flush=True)
                    continue
                    
                # 4b. 确认当前收盘价在 13 日均线之上 (生命线)
                if curr['收盘'] < curr['MA13']:
                    print(f"{status_msg} - NO MATCH (Failed: D0 Close Price Below MA13)", flush=True)
                    continue
                    
                # 4c. 确认当前收盘价接近 10 日或 13 日均线 (在 13 日均线 3% 范围内)
                if not (curr['收盘'] >= curr['MA13'] * 0.97 and curr['收盘'] <= curr['MA13'] * 1.03):
                    print(f"{status_msg} - NO MATCH (Failed: D0 Close not near MA13 (3% range))", flush=True)
                    continue
                
                
                # --- 5. 所有条件通过，发出信号 ---
                signal = '买入（严格缩量回马枪：放量突破涨停 + 不破下沿回调(10天) + 地量确认(MA5/3) + MA13支撑）'
                
                
            if signal:
                
                # 仅绘制包含所有指标的 K 线图
                df_plot = df_recent[['开盘', '最高', '最低', '收盘', '成交量', 'MA5', 'MA10', 'MA13', 'VOL_MA20']].copy()
                plot_k_line(df_plot, ts_code, name)
                
                # 使用中文列名
                selected.append({
                    '代码': ts_code, 
                    '名称': name,   
                    '当前收盘价': curr['收盘'],
                    'MA13': curr['MA13'],
                    '突破日': trigger_day_data['trade_date'],
                    '突破日开盘价': trigger_day_data['开盘'],
                    '信号': signal,
                })
                
                print(f"{status_msg} - MATCHED! Signal: {signal}", flush=True) 
            else:
                print(f"{status_msg} - NO MATCH", flush=True)

        except Exception as e:
            error_log_p2.append(f"Error processing {ts_code} in screening logic: {str(e)}")
            print(f"{status_msg} - FAILED (Logic Error: {e})", flush=True)
            continue
    
    # 统一写入所有日志文件
    all_errors = error_log_p1 + error_log_p2
    with open(ERROR_LOG_FILE, 'a', encoding='utf-8') as f:
        for log in all_errors:
            f.write(f"[{datetime.now()}] {log}\n") 
    
    results = pd.DataFrame(selected)
    print(f"[{datetime.now()}] --- PHASE 2 COMPLETED. {len(results)} stocks selected ---", flush=True)
    
    if not results.empty:
        results.to_csv(SELECTED_STOCKS_FILE, index=False, encoding='utf-8-sig')
        results.to_csv(SELECTED_STOCKS_INTERMEDIATE_FILE, index=False, encoding='utf-8-sig') 
        
        print(f"\n[{datetime.now()}] 筛选结果示例 (已保存到 {SELECTED_STOCKS_FILE})：", flush=True)
        print(results.head(), flush=True)
    
    return results

if __name__ == "__main__":
    
    # 检查本地数据目录是否存在
    if not os.path.exists('stock_data'):
        print(f"[{datetime.now()}] [CRITICAL ERROR] Local 'stock_data' directory not found.", flush=True)
        print(f"[{datetime.now()}] Please create a 'stock_data' directory and place the stock CSV files inside it (e.g., stock_data/000001.csv).", flush=True)
        exit(1)

    # 确保目标目录存在
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
    if not os.path.exists(K_LINE_PLOTS_DIR):
        os.makedirs(K_LINE_PLOTS_DIR)

    # 启动前打印文件路径信息
    print(f"[{datetime.now()}] Results will be saved to directory: {OUTPUT_DIR}", flush=True)
    print(f"[{datetime.now()}] Final CSV file: {SELECTED_STOCKS_FILE}", flush=True)
    print(f"[{datetime.now()}] Error Log file: {ERROR_LOG_FILE}", flush=True)

    # 确保新的错误日志文件被创建
    if not os.path.exists(ERROR_LOG_FILE):
         with open(ERROR_LOG_FILE, 'w', encoding='utf-8') as f:
             f.write(f"[{datetime.now()}] --- Starting Log for Run: {DATE_TIME_PREFIX} ---\n")

    stock_list = get_stock_list()
    # 确认总股票数量
    print(f"[{datetime.now()}] Total stocks fed into Phase 1: {len(stock_list)}", flush=True)
        
    results = asyncio.run(screen_stocks(stock_list))
    if not results.empty:
        print(f"\n[{datetime.now()}] Final Result: 筛选出 {len(results)} 只符合战法的股票，保存至 {SELECTED_STOCKS_FILE}", flush=True)
    else:
        print(f"\n[{datetime.now()}] Final Result: 未找到符合条件的股票", flush=True)
