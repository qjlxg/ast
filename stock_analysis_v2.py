import pandas as pd
import os
import glob
from datetime import datetime
import numpy as np
import warnings

# =========================================================
# ä¿®å¤ Pandas è­¦å‘Šé”™è¯¯
# å°† pd.core.common.SettingWithCopyWarning æ›¿æ¢ä¸º pd.errors.SettingWithCopyWarning
# =========================================================
try:
    # å°è¯•ä½¿ç”¨æ–°ç‰ˆæœ¬ Pandas çš„è·¯å¾„
    warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)
except AttributeError:
    # å¦‚æœå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ—§ç‰ˆæœ¬ Pandas çš„è·¯å¾„ (ä½œä¸ºå…¼å®¹æ€§å›é€€ï¼Œä½†é€šå¸¸æ–°ç‰ˆæœ¬ä¸åŒ…å«æ—§è·¯å¾„)
    try:
        warnings.filterwarnings('ignore', category=pd.core.common.SettingWithCopyWarning)
    except Exception:
        # å®åœ¨æ‰¾ä¸åˆ°å°±å¿½ç•¥ï¼Œä¸å½±å“æ ¸å¿ƒåŠŸèƒ½
        pass 

# --- é…ç½®å’Œè·¯å¾„è®¾ç½® ---
TODAY_DATE = datetime.now().strftime('%Y%m%d')

# 1. ç­›é€‰æ–‡ä»¶ï¼ˆåˆ—è¡¨æ¥æºï¼‰çš„åŸºç¡€ç›®å½•
RESULTS_BASE_DIR = 'results' 
# 2. åŸå§‹è‚¡ç¥¨å†å²æ•°æ®çš„ç›®å½• (ä¾‹å¦‚: stock_data/000001.csv)
STOCK_DATA_DIR = 'stock_data' 

# 3. æœ€ç»ˆè¾“å‡ºæ–‡ä»¶çš„ç›®å½•
OUTPUT_DIR = f'buy_signals/{TODAY_DATE}'
OUTPUT_FILE = os.path.join(OUTPUT_DIR, f'{TODAY_DATE}.csv')

# åŸå§‹æ•°æ®æ–‡ä»¶å¿…é¡»åŒ…å«çš„åˆ—å
REQUIRED_RAW_COLUMNS = ['æ—¥æœŸ', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'è‚¡ç¥¨ä»£ç ']

# æœ€ç»ˆè¾“å‡º CSV æ–‡ä»¶çš„åˆ—å
FINAL_OUTPUT_COLUMNS = [
    'æ—¥æœŸ', 'è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'ä¹°å…¥ä¿¡å·æ€»åˆ†', 'è§¦å‘ä¿¡å·',
    'æ”¶ç›˜ä»·', 'K', 'D', 'J', 'DIF', 'DEA'
]

# æ ¸å¿ƒè®¡ç®—å‚æ•°
MA_SHORT = 5
MA_LONG = 20
MACD_SHORT = 12
MACD_LONG = 26
MACD_SIGNAL = 9
KDJ_N = 9
KDJ_M1 = 3
KDJ_M2 = 3

# --- è¾…åŠ©å‡½æ•°ï¼šæŸ¥æ‰¾æœ€æ–°çš„ç­›é€‰åˆ—è¡¨æ–‡ä»¶ ---
def find_latest_master_file(base_dir=RESULTS_BASE_DIR):
    """æŸ¥æ‰¾ 'results' ç›®å½•ä¸‹æ‰€æœ‰å­ç›®å½•ä¸­æœ€æ–°ä¿®æ”¹çš„ CSV æ–‡ä»¶ä½œä¸ºåˆ†æåˆ—è¡¨"""
    all_files = glob.glob(os.path.join(base_dir, '**', '*.csv'), recursive=True)
    
    if not all_files:
        print(f"[DEBUG] â›”ï¸ åœ¨ {base_dir} åŠå…¶å­ç›®å½•ä¸­æœªæ‰¾åˆ°ä»»ä½• CSV æ–‡ä»¶ã€‚")
        return None
    
    latest_file = max(all_files, key=os.path.getmtime)
    print(f"[DEBUG] âœ… æ‰¾åˆ°æœ€æ–°çš„ç­›é€‰åˆ—è¡¨æ–‡ä»¶: {latest_file}")
    return latest_file

# --- æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å‡½æ•° ---
def add_technical_indicators(df):
    """ä»åŸå§‹æ•°æ®è®¡ç®— MA, MACD, KDJ æŒ‡æ ‡"""
    
    # ç¡®ä¿å…³é”®åˆ—ä¸ºæ•°å€¼ç±»å‹ï¼Œå¹¶å¤„ç†ç¼ºå¤±å€¼
    for col in ['æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½']:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    df = df.dropna(subset=['æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½']) # ç§»é™¤ä»·æ ¼æ•°æ®ç¼ºå¤±çš„è¡Œ

    # 1. å‡çº¿ (MA)
    df['MA5'] = df['æ”¶ç›˜'].rolling(window=MA_SHORT).mean()
    df['MA20'] = df['æ”¶ç›˜'].rolling(window=MA_LONG).mean()

    # 2. MACD
    ema_short = df['æ”¶ç›˜'].ewm(span=MACD_SHORT, adjust=False).mean()
    ema_long = df['æ”¶ç›˜'].ewm(span=MACD_LONG, adjust=False).mean()
    df['DIF'] = ema_short - ema_long
    df['DEA'] = df['DIF'].ewm(span=MACD_SIGNAL, adjust=False).mean()
    df['MACD_BAR'] = 2 * (df['DIF'] - df['DEA'])
    
    # 3. KDJ (RSV, K, D, J)
    df['LLV'] = df['æœ€ä½'].rolling(window=KDJ_N).min()
    df['HHV'] = df['æœ€é«˜'].rolling(window=KDJ_N).max()
    denominator = df['HHV'] - df['LLV']
    
    # RSV è®¡ç®— (å¤„ç†é™¤ä»¥é›¶çš„æƒ…å†µ)
    df['RSV'] = np.where(denominator == 0, 
                         50.0, 
                         (df['æ”¶ç›˜'] - df['LLV']) / denominator * 100)
                         
    df['K'] = df['RSV'].ewm(span=KDJ_M1, adjust=False).mean()
    df['D'] = df['K'].ewm(span=KDJ_M2, adjust=False).mean()
    df['J'] = 3 * df['K'] - 2 * df['D']
    
    df = df.drop(columns=['LLV', 'HHV', 'RSV'], errors='ignore')
    
    return df.dropna().rename(columns={'æ”¶ç›˜': 'æ”¶ç›˜ä»·'})

# --- è¯„åˆ†è§„åˆ™ ---
SCORE_RULES = {
    'KDJ_Reversal': {'score': 3, 'desc': 'KDJä½ä½åè½¬é‡‘å‰'},
    'MACD_GoldenCross': {'score': 3, 'desc': 'MACDé‡‘å‰'},
    'MACD_Bar_Positive': {'score': 2, 'desc': 'MACDæŸ±ä½“ç”±ç»¿è½¬çº¢'},
    'MA_Confirmation': {'score': 2, 'desc': 'çŸ­æœŸå‡çº¿å¤šå¤´ç¡®è®¤'}
}

# --- æ ¸å¿ƒåˆ†æå‡½æ•° ---
def calculate_buy_signal(df_stock, stock_name, code_str):
    """
    åŸºäºæœ€æ–°ä¸¤æœŸæ•°æ®ï¼Œè®¡ç®—ä¹°å…¥ä¿¡å·å¾—åˆ†ã€‚
    """
    if len(df_stock) < 2:
        print(f"[DEBUG] âš ï¸ {code_str} ({stock_name}): æ•°æ®è¡Œæ•°ä¸è¶³2è¡Œï¼Œæ— æ³•è®¡ç®—ä¿¡å·ã€‚")
        return None

    # è·å–æœ€æ–°ä¸€æœŸï¼ˆTodayï¼‰å’Œå‰ä¸€æœŸï¼ˆYesterdayï¼‰æ•°æ®
    latest = df_stock.iloc[-1]
    prev = df_stock.iloc[-2]

    # åˆå§‹åŒ–åˆ†æ•°å’Œä¿¡å·
    score = 0
    signals = []

    # C1: KDJ å¼ºåŠ¿åè½¬ (KDJ_Reversal) - 3åˆ†
    # KDJé‡‘å‰: K > D ä¸” K_prev <= D_prevï¼ŒåŒæ—¶ J å€¼ä½äº 50 (ç¡®ä¿æ˜¯ä½ä½åå¼¹)
    if (latest['K'] > latest['D']) and (prev['K'] <= prev['D']) and (latest['J'] < 50):
        score += SCORE_RULES['KDJ_Reversal']['score']
        signals.append(SCORE_RULES['KDJ_Reversal']['desc'])

    # C2: MACD é‡‘å‰ (MACD_GoldenCross) - 3åˆ†
    # MACDé‡‘å‰: DIF > DEA ä¸” DIF_prev <= DEA_prev
    if (latest['DIF'] > latest['DEA']) and (prev['DIF'] <= prev['DEA']):
        score += SCORE_RULES['MACD_GoldenCross']['score']
        signals.append(SCORE_RULES['MACD_GoldenCross']['desc'])

    # C3: MACD æŸ±ä½“ç¿»çº¢ (MACD_Bar_Positive) - 2åˆ†
    # MACDæŸ±ä½“ç¿»çº¢: MACD_BAR > 0 ä¸” MACD_BAR_prev <= 0
    if (latest['MACD_BAR'] > 0) and (prev['MACD_BAR'] <= 0):
        score += SCORE_RULES['MACD_Bar_Positive']['score']
        signals.append(SCORE_RULES['MACD_Bar_Positive']['desc'])

    # C4: çŸ­æœŸå‡çº¿ç¡®è®¤ (MA_Confirmation) - 2åˆ†
    # çŸ­æœŸå¤šå¤´æ’åˆ—: æ”¶ç›˜ä»· > MA5 ä¸” MA5 > MA20
    if (latest['æ”¶ç›˜ä»·'] > latest['MA5']) and (latest['MA5'] > latest['MA20']):
        score += SCORE_RULES['MA_Confirmation']['score']
        signals.append(SCORE_RULES['MA_Confirmation']['desc'])
    
    if score == 0:
        # print(f"[DEBUG] ğŸš« {code_str} ({stock_name}): æœªè§¦å‘ä»»ä½•ä¹°å…¥ä¿¡å· (æ€»åˆ† 0)ã€‚")
        return None

    print(f"[DEBUG] âœ¨ {code_str} ({stock_name}): å‘ç°ä¿¡å·! æ€»åˆ† {score}ã€‚")
    
    # æ„å»ºç»“æœå­—å…¸
    result = {
        'æ—¥æœŸ': latest['æ—¥æœŸ'],
        'è‚¡ç¥¨ä»£ç ': str(latest['è‚¡ç¥¨ä»£ç ']).zfill(6),
        'è‚¡ç¥¨åç§°': stock_name, # ä½¿ç”¨ä»ç­›é€‰åˆ—è¡¨è·å–çš„åç§°
        'ä¹°å…¥ä¿¡å·æ€»åˆ†': score,
        'è§¦å‘ä¿¡å·': 'ï¼Œ'.join(signals),
        'æ”¶ç›˜ä»·': latest['æ”¶ç›˜ä»·'],
        'K': round(latest['K'], 2),
        'D': round(latest['D'], 2),
        'J': round(latest['J'], 2),
        'DIF': round(latest['DIF'], 3),
        'DEA': round(latest['DEA'], 3),
    }
    return result

# --- ä¸»æ‰§è¡Œæµç¨‹ ---
def main():
    """ä¸»ç¨‹åºï¼Œè´Ÿè´£æ–‡ä»¶è¯»å–ã€è®¡ç®—æŒ‡æ ‡ã€åˆ†æå’Œç»“æœè¾“å‡º"""
    print(f"--- è‚¡ç¥¨å®šå‘ä¹°å…¥ä¿¡å·åˆ†æç¨‹åº ---")
    print(f"åˆ†ææ—¥æœŸ: {TODAY_DATE}")
    print(f"æ•°æ®ç›®å½•: {STOCK_DATA_DIR}")
    print(f"é¢„æœŸè¾“å‡ºæ–‡ä»¶: {OUTPUT_FILE}")

    # =========================================================
    # æ­¥éª¤ 1: è¯»å–æœ€æ–°çš„ç­›é€‰åˆ—è¡¨
    # =========================================================
    master_file_path = find_latest_master_file()
    
    if not master_file_path:
        print("é”™è¯¯: æ— æ³•ç»§ç»­ï¼Œæœªæ‰¾åˆ°ç­›é€‰åˆ—è¡¨æ–‡ä»¶ã€‚")
        return

    print(f"-> æ­£åœ¨ä»ç­›é€‰æ–‡ä»¶ {os.path.basename(master_file_path)} è¯»å–å¾…åˆ†æè‚¡ç¥¨åˆ—è¡¨...")
    try:
        # å°è¯•ä½¿ç”¨GBK/ANSIå’ŒUTF-8ä¸¤ç§å¸¸è§ç¼–ç è¯»å–
        try:
            selected_stocks_df = pd.read_csv(master_file_path, encoding='utf-8')
        except UnicodeDecodeError:
            selected_stocks_df = pd.read_csv(master_file_path, encoding='gbk') 
            
        
        # æ£€æŸ¥ç­›é€‰æ–‡ä»¶åˆ—åï¼Œå¹¶è¿›è¡Œæ ‡å‡†åŒ–
        col_map = {}
        for col in selected_stocks_df.columns:
            if 'è‚¡ç¥¨ä»£ç ' in col:
                col_map[col] = 'è‚¡ç¥¨ä»£ç '
            elif 'è‚¡ç¥¨åç§°' in col:
                col_map[col] = 'è‚¡ç¥¨åç§°'

        if 'è‚¡ç¥¨ä»£ç ' not in col_map.values() or 'è‚¡ç¥¨åç§°' not in col_map.values():
            print("é”™è¯¯: ç­›é€‰æ–‡ä»¶ç¼ºå°‘ 'è‚¡ç¥¨ä»£ç ' æˆ– 'è‚¡ç¥¨åç§°' åˆ—ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€‚")
            return
            
        selected_stocks_df.rename(columns=col_map, inplace=True)
            
        # å°†è‚¡ç¥¨ä»£ç å’Œåç§°æ˜ å°„æˆå­—å…¸
        selected_stocks_df['è‚¡ç¥¨ä»£ç '] = selected_stocks_df['è‚¡ç¥¨ä»£ç '].astype(str).str.zfill(6)
        stock_map = selected_stocks_df.set_index('è‚¡ç¥¨ä»£ç ')['è‚¡ç¥¨åç§°'].to_dict()
        
    except Exception as e:
        print(f"è¯»å–ç­›é€‰æ–‡ä»¶ {master_file_path} æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        return

    if not stock_map:
        print("é”™è¯¯: ç­›é€‰åˆ—è¡¨æ–‡ä»¶ä¸ºç©ºï¼Œæ²¡æœ‰è‚¡ç¥¨éœ€è¦åˆ†æã€‚")
        return

    print(f"-> å…±æ‰¾åˆ° {len(stock_map)} æ”¯è‚¡ç¥¨éœ€è¦è¿›è¡Œåˆ†æã€‚")
    all_results = []
    processed_count = 0
    
    # =========================================================
    # æ­¥éª¤ 2: å®šå‘åŠ è½½å’Œåˆ†æå†å²æ•°æ®
    # =========================================================
    for code_str, stock_name in stock_map.items():
        file_path = os.path.join(STOCK_DATA_DIR, f'{code_str}.csv')
        
        if not os.path.exists(file_path):
            continue
        
        processed_count += 1
        
        try:
            # å°è¯•ä½¿ç”¨ GBK/ANSI å’Œ UTF-8 ä¸¤ç§å¸¸è§ç¼–ç è¯»å–æ•°æ®æ–‡ä»¶
            try:
                df_raw = pd.read_csv(file_path, encoding='utf-8')
            except UnicodeDecodeError:
                df_raw = pd.read_csv(file_path, encoding='gbk')

            # æ£€æŸ¥å…³é”®åˆ—æ˜¯å¦å­˜åœ¨
            missing_cols = [col for col in REQUIRED_RAW_COLUMNS if col not in df_raw.columns]
            if missing_cols:
                print(f"[DEBUG] âš ï¸ æ–‡ä»¶ {code_str} ç¼ºå°‘å¿…è¦åŸå§‹åˆ—: {', '.join(missing_cols)}ï¼Œè·³è¿‡ã€‚")
                continue
            
            # æ’åºå¹¶è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            df_raw = df_raw.sort_values(by='æ—¥æœŸ', ascending=True).reset_index(drop=True)
            df_calculated = add_technical_indicators(df_raw.copy())

            if df_calculated.empty or len(df_calculated) < MA_LONG:
                 # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®æ¥è®¡ç®—é•¿å‘¨æœŸå‡çº¿
                 continue

            # è®¡ç®—ä¿¡å· 
            signal_data = calculate_buy_signal(df_calculated, stock_name, code_str)
            if signal_data:
                all_results.append(signal_data)
            
        except Exception as e:
            print(f"ä¸¥é‡è­¦å‘Š: å¤„ç†æ–‡ä»¶ {file_path} ({stock_name}) æ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {e}")
            
    # è½¬æ¢ä¸º DataFrame
    new_signals_df = pd.DataFrame(all_results)
    
    print(f"-> å®é™…åˆ†æäº† {processed_count} ä¸ªè‚¡ç¥¨æ–‡ä»¶ã€‚")
    print(f"-> å‘ç° {len(new_signals_df)} æ¡æ–°ä¿¡å·éœ€è¦å†™å…¥ã€‚")

    # =========================================================
    # æ­¥éª¤ 3: è¯»å–æ—§æ•°æ®å¹¶å»é‡è¿½åŠ 
    # =========================================================
    old_signals_df = pd.DataFrame()
    existing_records = set()
    if os.path.exists(OUTPUT_FILE):
        print("-> å‘ç°æ—§çš„ä¿¡å·æ–‡ä»¶ï¼Œæ­£åœ¨è¯»å–å¹¶è¿›è¡Œå»é‡è¿½åŠ ...")
        try:
            # å°è¯•ä½¿ç”¨ GBK/ANSI å’Œ UTF-8 ä¸¤ç§å¸¸è§ç¼–ç è¯»å–è¾“å‡ºæ–‡ä»¶
            try:
                old_signals_df = pd.read_csv(OUTPUT_FILE, encoding='utf-8')
            except UnicodeDecodeError:
                old_signals_df = pd.read_csv(OUTPUT_FILE, encoding='gbk')
            
            # æ•°æ®æ ‡å‡†åŒ–
            old_signals_df['è‚¡ç¥¨ä»£ç '] = old_signals_df['è‚¡ç¥¨ä»£ç '].astype(str).str.zfill(6)
            
            # è®°å½•å·²æœ‰çš„è®°å½•é”® (æ—¥æœŸ, è‚¡ç¥¨ä»£ç )
            existing_records = set(old_signals_df[['æ—¥æœŸ', 'è‚¡ç¥¨ä»£ç ']].apply(tuple, axis=1))

        except Exception as e:
            print(f"è­¦å‘Š: è¯»å–æ—§æ–‡ä»¶ {OUTPUT_FILE} å¤±è´¥: {e}ã€‚å°†è·³è¿‡æ—§æ•°æ®ã€‚")
            old_signals_df = pd.DataFrame()

    new_records_to_add = []
    if not new_signals_df.empty:
        for index, row in new_signals_df.iterrows():
            key = (row['æ—¥æœŸ'], row['è‚¡ç¥¨ä»£ç '])
            if key not in existing_records:
                new_records_to_add.append(row.to_dict())
            
    new_signals_df_filtered = pd.DataFrame(new_records_to_add)

    # åˆå¹¶æ–°æ—§æ•°æ®
    if not old_signals_df.empty and not old_signals_df.empty: # ç¡®ä¿æ—§æ•°æ®æœ‰æœ‰æ•ˆåˆ—
        final_df = pd.concat([old_signals_df, new_signals_df_filtered], ignore_index=True, sort=False)
    else:
        final_df = new_signals_df_filtered
        
    # æœ€ç»ˆæ’åºå’Œæ ¼å¼åŒ–
    if not final_df.empty:
        # ç¡®ä¿åˆ—å­˜åœ¨ä¸”ä¸ºæ•°å€¼å‹æ‰èƒ½æ’åº
        if 'ä¹°å…¥ä¿¡å·æ€»åˆ†' in final_df.columns:
            final_df['ä¹°å…¥ä¿¡å·æ€»åˆ†'] = pd.to_numeric(final_df['ä¹°å…¥ä¿¡å·æ€»åˆ†'], errors='coerce')
            final_df = final_df.sort_values(by=['ä¹°å…¥ä¿¡å·æ€»åˆ†', 'æ—¥æœŸ'], ascending=[False, True])
        
        final_df = final_df[FINAL_OUTPUT_COLUMNS] # ç¡®ä¿åˆ—é¡ºåº

    # =========================================================
    # æ­¥éª¤ 4: è¾“å‡ºç»“æœ
    # =========================================================
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    if final_df.empty:
        print("--- ä»»åŠ¡å®Œæˆ ---")
        print("-> ğŸš« æœ€ç»ˆç»“æœé›†ä¸ºç©ºï¼Œæœªå†™å…¥ä»»ä½•æ–‡ä»¶ã€‚")
    else:
        # ç»Ÿä¸€ä½¿ç”¨ UTF-8 ç¼–ç å†™å…¥
        final_df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8')
        print(f"--- ä»»åŠ¡å®Œæˆ ---")
        print(f"âœ… å·²å°† {len(new_records_to_add)} æ¡æ–°ä¿¡å·è¿½åŠ åˆ° {OUTPUT_FILE} ä¸­ã€‚")
        print(f"âœ… æœ€ç»ˆç»“æœåŒ…å« {len(final_df)} æ¡è®°å½•ï¼ˆå·²å»é‡ï¼‰ã€‚")

if __name__ == '__main__':
    main()
