import pandas as pd
import os
import glob
from datetime import datetime
import numpy as np
import warnings

# =========================================================
# ä¿®å¤ Pandas è­¦å‘Šé”™è¯¯
# =========================================================
try:
    # å°è¯•ä½¿ç”¨æ–°ç‰ˆæœ¬ Pandas çš„è·¯å¾„
    warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)
except AttributeError:
    # å…¼å®¹æ€§å›é€€
    try:
        warnings.filterwarnings('ignore', category=pd.core.common.SettingWithCopyWarning)
    except Exception:
        pass 

# --- é…ç½®å’Œè·¯å¾„è®¾ç½® ---
TODAY_DATE = datetime.now().strftime('%Y%m%d')

# 1. ç­›é€‰æ–‡ä»¶ï¼ˆåˆ—è¡¨æ¥æºï¼‰çš„åŸºç¡€ç›®å½•
RESULTS_BASE_DIR = 'results' 
# 2. åŸå§‹è‚¡ç¥¨å†å²æ•°æ®çš„ç›®å½• (ä¾‹å¦‚: stock_data/000001.csv)
STOCK_DATA_DIR = 'stock_data' 

# 3. æœ€ç»ˆè¾“å‡ºæ–‡ä»¶çš„ç›®å½•
OUTPUT_DIR = f'buy_signals/{TODAY_DATE}'
OUTPUT_FILE = os.path.join(OUTPUT_DIR, f'{TODAY_DATE}.csv')

# åŸå§‹æ•°æ®æ–‡ä»¶å¿…é¡»åŒ…å«çš„åˆ—å
REQUIRED_RAW_COLUMNS = ['æ—¥æœŸ', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'è‚¡ç¥¨ä»£ç ']

# æœ€ç»ˆè¾“å‡º CSV æ–‡ä»¶çš„åˆ—å
FINAL_OUTPUT_COLUMNS = [
    'æ—¥æœŸ', 'è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'ä¹°å…¥ä¿¡å·æ€»åˆ†', 'è§¦å‘ä¿¡å·',
    'æ”¶ç›˜ä»·', 'K', 'D', 'J', 'DIF', 'DEA'
]

# æ ¸å¿ƒè®¡ç®—å‚æ•°
MA_SHORT = 5
MA_LONG = 20
MACD_SHORT = 12
MACD_LONG = 26
MACD_SIGNAL = 9
KDJ_N = 9
KDJ_M1 = 3
KDJ_M2 = 3

# --- è¾…åŠ©å‡½æ•°ï¼šåˆå¹¶æ‰€æœ‰ç­›é€‰åˆ—è¡¨æ–‡ä»¶ (æ–°é€»è¾‘) ---
def merge_all_master_files(base_dir=RESULTS_BASE_DIR):
    """æŸ¥æ‰¾ 'results' ç›®å½•ä¸‹æ‰€æœ‰ CSV æ–‡ä»¶ï¼Œè¯»å–å¹¶åˆå¹¶æˆä¸€ä¸ªå»é‡åçš„è‚¡ç¥¨åˆ—è¡¨"""
    # é€’å½’æŸ¥æ‰¾ base_dir åŠå…¶æ‰€æœ‰å­ç›®å½•ä¸­çš„æ‰€æœ‰ CSV æ–‡ä»¶
    all_files = glob.glob(os.path.join(base_dir, '**', '*.csv'), recursive=True)
    
    if not all_files:
        print(f"[DEBUG] â›”ï¸ åœ¨ {base_dir} åŠå…¶å­ç›®å½•ä¸­æœªæ‰¾åˆ°ä»»ä½• CSV æ–‡ä»¶ã€‚")
        return None
    
    print(f"[DEBUG] âœ… æ‰¾åˆ° {len(all_files)} ä¸ªç­›é€‰åˆ—è¡¨æ–‡ä»¶ï¼Œå¼€å§‹åˆå¹¶...")
    
    all_stocks = pd.DataFrame()
    for file_path in all_files:
        try:
            # å°è¯•ä½¿ç”¨ UTF-8 å’Œ GBK ä¸¤ç§å¸¸è§ç¼–ç è¯»å–
            try:
                df = pd.read_csv(file_path, encoding='utf-8')
            except UnicodeDecodeError:
                df = pd.read_csv(file_path, encoding='gbk') 
                
            # æ ‡å‡†åŒ–åˆ—åï¼Œç¡®ä¿åŒ…å« 'è‚¡ç¥¨ä»£ç ' å’Œ 'è‚¡ç¥¨åç§°'
            col_map = {}
            for col in df.columns:
                if 'è‚¡ç¥¨ä»£ç ' in col:
                    col_map[col] = 'è‚¡ç¥¨ä»£ç '
                elif 'è‚¡ç¥¨åç§°' in col:
                    col_map[col] = 'è‚¡ç¥¨åç§°'

            if 'è‚¡ç¥¨ä»£ç ' not in col_map.values():
                print(f"[DEBUG] âš ï¸ æ–‡ä»¶ {os.path.basename(file_path)} ç¼ºå°‘ 'è‚¡ç¥¨ä»£ç ' åˆ—ï¼Œè·³è¿‡ã€‚")
                continue
            
            # å¦‚æœç¼ºå°‘è‚¡ç¥¨åç§°ï¼Œåˆ™æ·»åŠ ä¸€ä¸ªç©ºåˆ—
            if 'è‚¡ç¥¨åç§°' not in col_map.values():
                df['è‚¡ç¥¨åç§°'] = 'æœªçŸ¥'
                col_map[df.columns[-1]] = 'è‚¡ç¥¨åç§°' # ç¡®ä¿è‚¡ç¥¨åç§°åˆ—åæ˜¯æ ‡å‡†åŒ–çš„

            df.rename(columns=col_map, inplace=True)
            
            # åªä¿ç•™å…³é”®åˆ—
            df = df[['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°']].copy()
            
            all_stocks = pd.concat([all_stocks, df], ignore_index=True)

        except Exception as e:
            print(f"è­¦å‘Š: è¯»å–ç­›é€‰æ–‡ä»¶ {os.path.basename(file_path)} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            continue

    if all_stocks.empty:
        return None

    # å»é‡å¹¶æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
    all_stocks['è‚¡ç¥¨ä»£ç '] = all_stocks['è‚¡ç¥¨ä»£ç '].astype(str).str.zfill(6)
    all_stocks.drop_duplicates(subset=['è‚¡ç¥¨ä»£ç '], inplace=True)

    print(f"[DEBUG] âœ… åˆå¹¶å»é‡åï¼Œå…±å¾—åˆ° {len(all_stocks)} æ”¯å¾…åˆ†æè‚¡ç¥¨ã€‚")
    return all_stocks

# --- æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å‡½æ•° (ä¿æŒä¸å˜) ---
def add_technical_indicators(df):
    """ä»åŸå§‹æ•°æ®è®¡ç®— MA, MACD, KDJ æŒ‡æ ‡"""
    
    for col in ['æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½']:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    df = df.dropna(subset=['æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½']) 

    df['MA5'] = df['æ”¶ç›˜'].rolling(window=MA_SHORT).mean()
    df['MA20'] = df['æ”¶ç›˜'].rolling(window=MA_LONG).mean()

    ema_short = df['æ”¶ç›˜'].ewm(span=MACD_SHORT, adjust=False).mean()
    ema_long = df['æ”¶ç›˜'].ewm(span=MACD_LONG, adjust=False).mean()
    df['DIF'] = ema_short - ema_long
    df['DEA'] = df['DIF'].ewm(span=MACD_SIGNAL, adjust=False).mean()
    df['MACD_BAR'] = 2 * (df['DIF'] - df['DEA'])
    
    df['LLV'] = df['æœ€ä½'].rolling(window=KDJ_N).min()
    df['HHV'] = df['æœ€é«˜'].rolling(window=KDJ_N).max()
    denominator = df['HHV'] - df['LLV']
    
    df['RSV'] = np.where(denominator == 0, 
                         50.0, 
                         (df['æ”¶ç›˜'] - df['LLV']) / denominator * 100)
                         
    df['K'] = df['RSV'].ewm(span=KDJ_M1, adjust=False).mean()
    df['D'] = df['K'].ewm(span=KDJ_M2, adjust=False).mean()
    df['J'] = 3 * df['K'] - 2 * df['D']
    
    df = df.drop(columns=['LLV', 'HHV', 'RSV'], errors='ignore')
    
    return df.dropna().rename(columns={'æ”¶ç›˜': 'æ”¶ç›˜ä»·'})

# --- æ ¸å¿ƒåˆ†æå‡½æ•° (ä¿æŒä¸å˜) ---
SCORE_RULES = {
    'KDJ_Reversal': {'score': 3, 'desc': 'KDJä½ä½åè½¬é‡‘å‰'},
    'MACD_GoldenCross': {'score': 3, 'desc': 'MACDé‡‘å‰'},
    'MACD_Bar_Positive': {'score': 2, 'desc': 'MACDæŸ±ä½“ç”±ç»¿è½¬çº¢'},
    'MA_Confirmation': {'score': 2, 'desc': 'çŸ­æœŸå‡çº¿å¤šå¤´ç¡®è®¤'}
}

def calculate_buy_signal(df_stock, stock_name, code_str):
    """åŸºäºæœ€æ–°ä¸¤æœŸæ•°æ®ï¼Œè®¡ç®—ä¹°å…¥ä¿¡å·å¾—åˆ†ã€‚"""
    if len(df_stock) < 2:
        return None

    latest = df_stock.iloc[-1]
    prev = df_stock.iloc[-2]
    score = 0
    signals = []

    # C1: KDJ å¼ºåŠ¿åè½¬
    if (latest['K'] > latest['D']) and (prev['K'] <= prev['D']) and (latest['J'] < 50):
        score += SCORE_RULES['KDJ_Reversal']['score']
        signals.append(SCORE_RULES['KDJ_Reversal']['desc'])

    # C2: MACD é‡‘å‰
    if (latest['DIF'] > latest['DEA']) and (prev['DIF'] <= prev['DEA']):
        score += SCORE_RULES['MACD_GoldenCross']['score']
        signals.append(SCORE_RULES['MACD_GoldenCross']['desc'])

    # C3: MACD æŸ±ä½“ç¿»çº¢
    if (latest['MACD_BAR'] > 0) and (prev['MACD_BAR'] <= 0):
        score += SCORE_RULES['MACD_Bar_Positive']['score']
        signals.append(SCORE_RULES['MACD_Bar_Positive']['desc'])

    # C4: çŸ­æœŸå‡çº¿ç¡®è®¤
    if (latest['æ”¶ç›˜ä»·'] > latest['MA5']) and (latest['MA5'] > latest['MA20']):
        score += SCORE_RULES['MA_Confirmation']['score']
        signals.append(SCORE_RULES['MA_Confirmation']['desc'])
    
    if score == 0:
        return None

    print(f"[DEBUG] âœ¨ {code_str} ({stock_name}): å‘ç°ä¿¡å·! æ€»åˆ† {score}ã€‚")
    
    result = {
        'æ—¥æœŸ': latest['æ—¥æœŸ'],
        'è‚¡ç¥¨ä»£ç ': str(latest['è‚¡ç¥¨ä»£ç ']).zfill(6),
        'è‚¡ç¥¨åç§°': stock_name,
        'ä¹°å…¥ä¿¡å·æ€»åˆ†': score,
        'è§¦å‘ä¿¡å·': 'ï¼Œ'.join(signals),
        'æ”¶ç›˜ä»·': latest['æ”¶ç›˜ä»·'],
        'K': round(latest['K'], 2),
        'D': round(latest['D'], 2),
        'J': round(latest['J'], 2),
        'DIF': round(latest['DIF'], 3),
        'DEA': round(latest['DEA'], 3),
    }
    return result

# --- ä¸»æ‰§è¡Œæµç¨‹ ---
def main():
    """ä¸»ç¨‹åºï¼Œè´Ÿè´£æ–‡ä»¶è¯»å–ã€è®¡ç®—æŒ‡æ ‡ã€åˆ†æå’Œç»“æœè¾“å‡º"""
    print(f"--- è‚¡ç¥¨å®šå‘ä¹°å…¥ä¿¡å·åˆ†æç¨‹åº ---")
    print(f"åˆ†ææ—¥æœŸ: {TODAY_DATE}")
    print(f"æ•°æ®ç›®å½•: {STOCK_DATA_DIR}")
    print(f"é¢„æœŸè¾“å‡ºæ–‡ä»¶: {OUTPUT_FILE}")

    # =========================================================
    # æ­¥éª¤ 1: è¯»å–å¹¶åˆå¹¶æ‰€æœ‰ç­›é€‰åˆ—è¡¨ (æ–°é€»è¾‘)
    # =========================================================
    selected_stocks_df = merge_all_master_files()
    
    if selected_stocks_df is None or selected_stocks_df.empty:
        print("é”™è¯¯: æ— æ³•ç»§ç»­ï¼Œåˆå¹¶åçš„ç­›é€‰åˆ—è¡¨ä¸ºç©ºã€‚")
        return
        
    # å°†åˆå¹¶åçš„åˆ—è¡¨è½¬æ¢ä¸ºå­—å…¸ï¼Œä»¥ä¾¿å¿«é€ŸæŸ¥æ‰¾
    stock_map = selected_stocks_df.set_index('è‚¡ç¥¨ä»£ç ')['è‚¡ç¥¨åç§°'].to_dict()

    print(f"-> æœ€ç»ˆå¾…åˆ†æè‚¡ç¥¨æ€»æ•°: {len(stock_map)} æ”¯ã€‚")
    all_results = []
    processed_count = 0
    
    # =========================================================
    # æ­¥éª¤ 2: å®šå‘åŠ è½½å’Œåˆ†æå†å²æ•°æ® (ä¿æŒä¸å˜)
    # =========================================================
    for code_str, stock_name in stock_map.items():
        file_path = os.path.join(STOCK_DATA_DIR, f'{code_str}.csv')
        
        if not os.path.exists(file_path):
            continue
        
        processed_count += 1
        
        try:
            # å°è¯•ä½¿ç”¨ GBK/ANSI å’Œ UTF-8 ä¸¤ç§å¸¸è§ç¼–ç è¯»å–æ•°æ®æ–‡ä»¶
            try:
                df_raw = pd.read_csv(file_path, encoding='utf-8')
            except UnicodeDecodeError:
                df_raw = pd.read_csv(file_path, encoding='gbk')

            # æ£€æŸ¥å…³é”®åˆ—æ˜¯å¦å­˜åœ¨
            missing_cols = [col for col in REQUIRED_RAW_COLUMNS if col not in df_raw.columns]
            if missing_cols:
                # print(f"[DEBUG] âš ï¸ æ–‡ä»¶ {code_str} ç¼ºå°‘å¿…è¦åŸå§‹åˆ—: {', '.join(missing_cols)}ï¼Œè·³è¿‡ã€‚")
                continue
            
            # æ’åºå¹¶è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            df_raw = df_raw.sort_values(by='æ—¥æœŸ', ascending=True).reset_index(drop=True)
            df_calculated = add_technical_indicators(df_raw.copy())

            if df_calculated.empty or len(df_calculated) < MA_LONG:
                 continue

            # è®¡ç®—ä¿¡å· 
            signal_data = calculate_buy_signal(df_calculated, stock_name, code_str)
            if signal_data:
                all_results.append(signal_data)
            
        except Exception as e:
            print(f"ä¸¥é‡è­¦å‘Š: å¤„ç†æ–‡ä»¶ {file_path} ({stock_name}) æ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {e}")
            
    # è½¬æ¢ä¸º DataFrame
    new_signals_df = pd.DataFrame(all_results)
    
    print(f"-> å®é™…åˆ†æäº† {processed_count} ä¸ªè‚¡ç¥¨æ–‡ä»¶ã€‚")
    print(f"-> å‘ç° {len(new_signals_df)} æ¡æ–°ä¿¡å·éœ€è¦å†™å…¥ã€‚")

    # =========================================================
    # æ­¥éª¤ 3: è¯»å–æ—§æ•°æ®å¹¶å»é‡è¿½åŠ 
    # =========================================================
    old_signals_df = pd.DataFrame()
    existing_records = set()
    if os.path.exists(OUTPUT_FILE):
        print("-> å‘ç°æ—§çš„ä¿¡å·æ–‡ä»¶ï¼Œæ­£åœ¨è¯»å–å¹¶è¿›è¡Œå»é‡è¿½åŠ ...")
        try:
            try:
                old_signals_df = pd.read_csv(OUTPUT_FILE, encoding='utf-8')
            except UnicodeDecodeError:
                old_signals_df = pd.read_csv(OUTPUT_FILE, encoding='gbk')
            
            old_signals_df['è‚¡ç¥¨ä»£ç '] = old_signals_df['è‚¡ç¥¨ä»£ç '].astype(str).str.zfill(6)
            existing_records = set(old_signals_df[['æ—¥æœŸ', 'è‚¡ç¥¨ä»£ç ']].apply(tuple, axis=1))

        except Exception as e:
            print(f"è­¦å‘Š: è¯»å–æ—§æ–‡ä»¶ {OUTPUT_FILE} å¤±è´¥: {e}ã€‚å°†è·³è¿‡æ—§æ•°æ®ã€‚")
            old_signals_df = pd.DataFrame()

    new_records_to_add = []
    if not new_signals_df.empty:
        for index, row in new_signals_df.iterrows():
            key = (row['æ—¥æœŸ'], row['è‚¡ç¥¨ä»£ç '])
            if key not in existing_records:
                new_records_to_add.append(row.to_dict())
            
    new_signals_df_filtered = pd.DataFrame(new_records_to_add)

    # åˆå¹¶æ–°æ—§æ•°æ®
    if not old_signals_df.empty: 
        final_df = pd.concat([old_signals_df, new_signals_df_filtered], ignore_index=True, sort=False)
    else:
        final_df = new_signals_df_filtered
        
    # æœ€ç»ˆæ’åºå’Œæ ¼å¼åŒ– (æŒ‰è¯„åˆ†é«˜ä½æ’åˆ—)
    if not final_df.empty:
        if 'ä¹°å…¥ä¿¡å·æ€»åˆ†' in final_df.columns:
            final_df['ä¹°å…¥ä¿¡å·æ€»åˆ†'] = pd.to_numeric(final_df['ä¹°å…¥ä¿¡å·æ€»åˆ†'], errors='coerce')
            # å…³é”®ï¼šæŒ‰ 'ä¹°å…¥ä¿¡å·æ€»åˆ†' é™åºæ’åˆ— (è¯„åˆ†é«˜ä½)
            final_df = final_df.sort_values(by=['ä¹°å…¥ä¿¡å·æ€»åˆ†', 'æ—¥æœŸ'], ascending=[False, True])
        
        final_df = final_df[FINAL_OUTPUT_COLUMNS] 

    # =========================================================
    # æ­¥éª¤ 4: è¾“å‡ºç»“æœ
    # =========================================================
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    if final_df.empty:
        print("--- ä»»åŠ¡å®Œæˆ ---")
        print("-> ğŸš« æœ€ç»ˆç»“æœé›†ä¸ºç©ºï¼Œæœªå†™å…¥ä»»ä½•æ–‡ä»¶ã€‚")
    else:
        # ç»Ÿä¸€ä½¿ç”¨ UTF-8 ç¼–ç å†™å…¥
        final_df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8')
        print(f"--- ä»»åŠ¡å®Œæˆ ---")
        print(f"âœ… å·²å°† {len(new_records_to_add)} æ¡æ–°ä¿¡å·è¿½åŠ åˆ° {OUTPUT_FILE} ä¸­ã€‚")
        print(f"âœ… æœ€ç»ˆç»“æœåŒ…å« {len(final_df)} æ¡è®°å½•ï¼ˆå·²å»é‡ï¼‰ï¼Œå·²æŒ‰è¯„åˆ†é«˜ä½æ’åºã€‚")

if __name__ == '__main__':
    main()
